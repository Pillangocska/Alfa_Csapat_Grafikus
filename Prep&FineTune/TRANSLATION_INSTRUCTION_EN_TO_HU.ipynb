{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNd6ZneRFcobPkCaIPU6cyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bambika69/Alfa_Csapat_Grafikus/blob/main/Prep%26FineTune/TRANSLATION_INSTRUCTION_EN_TO_HU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpgGc_bL5x49",
        "outputId": "8ad70f7f-7142-48bc-ad9c-bac97388d14a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
      ],
      "metadata": {
        "id": "8bLxcW666CNS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tloen/alpaca-lora.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC7Bzm-76UZ4",
        "outputId": "e98bb415-4136-41f0-b302-8540f4c449af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'alpaca-lora'...\n",
            "remote: Enumerating objects: 607, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 607 (delta 28), reused 33 (delta 19), pack-reused 556\u001b[K\n",
            "Receiving objects: 100% (607/607), 27.78 MiB | 6.81 MiB/s, done.\n",
            "Resolving deltas: 100% (360/360), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-hu\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-hu\")"
      ],
      "metadata": {
        "id": "bc9f0KeH6GR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "zBMxZOkd9cRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def reduce_json_size(input_file, output_file):\n",
        "    # Read the JSON file into a pandas DataFrame\n",
        "    df = pd.read_json(input_file)\n",
        "\n",
        "    # Calculate the number of elements to keep\n",
        "    reduced_size = len(df) // 4\n",
        "\n",
        "    # Keep only the desired elements\n",
        "    reduced_df = df[:reduced_size]\n",
        "\n",
        "    # Write the reduced data to a JSON file\n",
        "    reduced_df.to_json(output_file, orient='records', indent=4)\n",
        "\n",
        "# Usage example\n",
        "reduce_json_size(\"/content/alpaca-lora/alpaca_data.json\", \"/content/alpaca-lora/reduced.json\")"
      ],
      "metadata": {
        "id": "BbQ2pw3p9gZq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_reduced_data = json.load(open(\"/content/alpaca-lora/reduced.json\", \"r\"))\n",
        "alpaca_original_data = json.load(open(\"/content/alpaca-lora/alpaca_data.json\", \"r\"))"
      ],
      "metadata": {
        "id": "jp3SSk1_94zQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(alpaca_original_data[-1])\n",
        "print(alpaca_reduced_data[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zimkih8X96VX",
        "outputId": "fc4a618b-c9bf-4674-cd31-1b5f0880f795"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Analyze the given legal document and explain the key points.', 'input': 'The following is an excerpt from a contract between two parties, labeled \"Company A\" and \"Company B\": \\n\\n\"Company A agrees to provide reasonable assistance to Company B in ensuring the accuracy of the financial statements it provides. This includes allowing Company A reasonable access to personnel and other documents which may be necessary for Company B’s review. Company B agrees to maintain the document provided by Company A in confidence, and will not disclose the information to any third parties without Company A’s explicit permission.\"', 'output': 'This legal document states that Company A has agreed to provide reasonable assistance to Company B in ensuring the accuracy of the financial statements. Company A has also agreed to allow Company B to access personnel and other documents necessary for Company B’s review. Company B, in turn, has accepted responsibility to maintain the confidentiality of the data provided by Company A and will not disclose it to any third parties without explicit permission. As such, both companies have agreed to fulfill their respective obligations with respect to the accuracy of the financial statements.\\n##\\n10. Instruction: Rewrite the following sentence using the active voice.\\n10. Input:\\nThe book was read by the student.  \\n10. Output:\\nThe student read the book.'}\n",
            "{'instruction': 'Given two texts, find the most similar sentence in each text.', 'input': 'Text 1: The giant rose petals were floating in the breeze. \\nText 2: The petals of the sunflower swayed in the wind.', 'output': 'Text 1: The giant rose petals were floating in the breeze. \\nText 2: The petals of the sunflower swayed in the wind.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation_EN_to_HU\", model=model, tokenizer=tokenizer, max_length=1024)"
      ],
      "metadata": {
        "id": "UjKQHm3H60mm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_hun_data = []\n",
        "for conversation in tqdm(alpaca_reduced_data):\n",
        "    conv_hu = dict()\n",
        "    \n",
        "    try:\n",
        "        if any(conversation[\"input\"]):\n",
        "    \n",
        "            conv_inst = conversation[\"instruction\"]\n",
        "            conv_input = conversation[\"input\"]\n",
        "            conv_output = conversation[\"output\"]\n",
        "\n",
        "            \n",
        "    \n",
        "            conv_hu[\"instruction\"] = translator(conv_inst)[0][\"translation_text\"]\n",
        "            conv_hu[\"input\"] = translator(conv_input)[0][\"translation_text\"]\n",
        "            conv_hu[\"output\"] = translator(conv_output)[0][\"translation_text\"]\n",
        "        else:\n",
        "            conv_inst = conversation[\"instruction\"]\n",
        "            conv_output = conversation[\"output\"]\n",
        "\n",
        "            conv_hu[\"instruction\"] = translator(conv_inst)[0][\"translation_text\"]\n",
        "            conv_hu[\"input\"] = \"\"\n",
        "            conv_hu[\"output\"] = translator(conv_output)[0][\"translation_text\"]\n",
        "    except Exception as e:\n",
        "         print(e)\n",
        "    alpaca_hun_data.append(conv_hu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJSi2bHi6_j2",
        "outputId": "c9c9305e-6528-415e-8715-aef7261bc38c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 5428/13000 [3:30:33<5:02:32,  2.40s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            " 48%|████▊     | 6285/13000 [4:04:30<5:58:45,  3.21s/it]Your input_length: 940 is bigger than 0.9 * max_length: 1024. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
            "100%|██████████| 13000/13000 [8:35:58<00:00,  2.38s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verified_alpaca_data = []\n",
        "i = 0\n",
        "for row in tqdm(alpaca_hun_data):\n",
        "    if row.get(\"instruction\") and row.get(\"output\"):\n",
        "        verified_alpaca_data.append(row)\n",
        "    else:\n",
        "        print(row)\n",
        "        i += 1\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT9gbw4t_MEP",
        "outputId": "baaa42d2-b898-41ee-bed2-d71d6328fbf9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13000/13000 [00:00<00:00, 1070353.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Az alábbi mondat fordítása japánul', 'input': 'Ő egy kiváló tanár.', 'output': ''}\n",
            "{'instruction': 'Válassz egy hangulatjelet, amely a legjobban leírja a következő hangulatot.', 'input': 'Izgatott', 'output': ''}\n",
            "{'instruction': 'A következő Unicode-szöveg konvertálása ASCII-be', 'input': '\"U0001F608\"', 'output': ''}\n",
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(verified_alpaca_data)\n",
        "json.dump(verified_alpaca_data, open(\"/content/alpaca-lora/alpaca_data_hu_verified.json\", \"w\"))"
      ],
      "metadata": {
        "id": "wgvdbXt4_SOm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9PykYBvY1iKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}